from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader

from tqdm import tqdm
import os

print("ðŸš€ Indexador iniciado")

# ---------------------------
# CONFIG
# ---------------------------
DOCS_PATH = "docs/markdown"
DB_PATH = "db"
BATCH_SIZE = 25

# ---------------------------
# LOAD DOCUMENTS
# ---------------------------
loader = DirectoryLoader(
    DOCS_PATH,
    glob="**/*.md",
    loader_cls=TextLoader,
    show_progress=True
)

documents = loader.load()
print(f"ðŸ“„ {len(documents)} documentos carregados")

# ---------------------------
# SPLIT DOCUMENTS
# ---------------------------
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

splits = text_splitter.split_documents(documents)
print(f"ðŸ§© {len(splits)} chunks gerados")

# ---------------------------
# EMBEDDINGS
# ---------------------------
print("ðŸ§  Inicializando embeddings")
embeddings = OllamaEmbeddings(
    model="nomic-embed-text"
)

# ---------------------------
# VECTOR STORE
# ---------------------------
print("ðŸ“¦ Criando / abrindo Chroma")
vectorstore = Chroma(
    persist_directory=DB_PATH,
    embedding_function=embeddings
)

# ---------------------------
# INDEXAÃ‡ÃƒO EM BATCHES
# ---------------------------
print("ðŸ“¦ Iniciando indexaÃ§Ã£o em batches")

for i in range(0, len(splits), BATCH_SIZE):
    batch = splits[i:i + BATCH_SIZE]
    print(f"ðŸ”„ Indexando chunks {i} â†’ {i + len(batch)}")
    vectorstore.add_documents(batch)


print("âœ… IndexaÃ§Ã£o concluÃ­da com sucesso")
